{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82164c3-cd8f-48cf-9595-426c356d47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_prefix=\"multiclass_resnet-indep_\"\n",
    "\n",
    "train_folder=\"./train-val-independent/train/\"\n",
    "valid_folder=\"./train-val-independent/validation/\"\n",
    "train_csv = \"./csv_resnet_indep/trainData.csv\"\n",
    "valid_csv = \"./csv_resnet_indep/valiData.csv\"\n",
    "\n",
    "b_selfattention=True\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "start_model_path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f4f87-90ba-4d24-8399-d65d29ecebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2a23f-54d6-4445-a1a6-a9af1ac44bfa",
   "metadata": {},
   "source": [
    "# neural network\n",
    "\n",
    "paper: \"Acoustic Identification of Ae. aegypti Mosquitoes using Smartphone Apps and Residual Convolutional Neural Networks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163076a6-11e0-443a-bf32-e11caa0e85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3)):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)  # Updated to BatchNorm2d for spatial inputs\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)  # Updated to BatchNorm2d for spatial inputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.norm1(self.conv1(x)))\n",
    "        x = self.norm2(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "class ClassificationBlock(nn.Module):\n",
    "    def __init__(self, in_features, cls_num):\n",
    "        super(ClassificationBlock, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features, 256)\n",
    "        self.fc2 = nn.Linear(256, cls_num)\n",
    "        self.cls_num=cls_num\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ProposedModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_residual_blocks=3, base_filters=64, kernel_size=(3, 3), cls_num=2):\n",
    "        super(ProposedModel, self).__init__()\n",
    "        self.initial_conv = nn.Conv2d(input_channels, base_filters, kernel_size=kernel_size, padding=1)\n",
    "        self.arrangements = nn.ModuleList()\n",
    "        for _ in range(num_residual_blocks):\n",
    "            self.arrangements.append(\n",
    "                nn.Sequential(\n",
    "                    ResidualBlock(base_filters, base_filters),\n",
    "                    nn.MaxPool2d((2, 2)),\n",
    "                    nn.Dropout(0.2)\n",
    "                )\n",
    "            )\n",
    "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive pooling to ensure consistent feature size\n",
    "        self.classification_block = ClassificationBlock(base_filters, cls_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.initial_conv(x))\n",
    "        for arrangement in self.arrangements:\n",
    "            x = arrangement(x)\n",
    "        x = self.final_pool(x)  # Ensure output size is (N, base_filters, 1, 1)\n",
    "        x = self.classification_block(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6858c2-6f6f-4331-b009-cb46a310fb1d",
   "metadata": {},
   "source": [
    "# data - spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa3a90-97e2-45c4-a618-8ca02e3d8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "\n",
    "# normalize the spectrogram\n",
    "def spec_normalization(spec, err=1e-6):\n",
    "    mean, std = spec.mean(), spec.std()\n",
    "    spec = (spec - mean) / (std + err)\n",
    "    return spec\n",
    "\n",
    "\n",
    "# transfer from 2 channels spectrogram to 3 channels image\n",
    "def spec_img(spec):\n",
    "    spec = spec_normalization(spec)\n",
    "    spec_min, spec_max = spec.min(), spec.max()\n",
    "    spec = 255 * (spec - spec_min) / (spec_max - spec_min)\n",
    "    spec = spec.astype(np.uint8)\n",
    "    spec = spec[np.newaxis, ...]\n",
    "    #print(spec.shape)\n",
    "    return spec\n",
    "\n",
    "\n",
    "# data augmentation on time domain and frequency domain in spectrogram image - have 3 channels\n",
    "def specaug(mel_spectrogram, frequency_masking_para=1,\n",
    "            time_masking_para=1, frequency_mask_num=1, time_mask_num=1):\n",
    "    \"\"\"\n",
    "        Modified from SpecAugment\n",
    "        Author: Demis TaeKyu Eom and Evangelos Kazakos\n",
    "        License: https://github.com/DemisEom/SpecAugment/blob/master/LICENSE\n",
    "        Code URL: https://github.com/DemisEom/SpecAugment/blob/master/SpecAugment/spec_augment_pytorch.py\n",
    "    \"\"\"\n",
    "    v = mel_spectrogram.shape[1]\n",
    "    tau = mel_spectrogram.shape[2]\n",
    "    # Frequency masking\n",
    "    for i in range(frequency_mask_num):\n",
    "        f = np.random.uniform(low=0.0, high=frequency_masking_para)\n",
    "        f = int(f)\n",
    "        f0 = random.randint(0, v - f)\n",
    "        mel_spectrogram[:, f0:f0 + f, :] = 0\n",
    "\n",
    "    # Time masking\n",
    "    for i in range(time_mask_num):\n",
    "        t = np.random.uniform(low=0.0, high=time_masking_para)\n",
    "        t = int(t)\n",
    "        t0 = random.randint(0, tau - t)\n",
    "        mel_spectrogram[:, :, t0:t0 + t] = 0\n",
    "    return mel_spectrogram\n",
    "\n",
    "\n",
    "# Store data into Dataset\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, label_file, label_list, d_type=None):\n",
    "        self.label_file = pd.read_csv(label_file)\n",
    "        self.label_list = label_list\n",
    "        self.transform = transforms.ToTensor()\n",
    "        self.d_type = d_type\n",
    "    \n",
    "        self.specs = []\n",
    "        self.labels = []\n",
    "        self.fns = []\n",
    "\n",
    "        for i in range(len(self.label_file)):\n",
    "            audio_path = self.label_file.iloc[i]['Fname']\n",
    "            self.fns.append(audio_path)\n",
    "           \n",
    "            spec = get_melspec(audio_path)\n",
    "            spec = spec_img(spec)\n",
    "\n",
    "            self.specs.append(spec)\n",
    "\n",
    "            # get its label\n",
    "            label_class = self.label_file.iloc[i]['Species']\n",
    "            #print(label_class)\n",
    "            label = torch.tensor(self.label_list[label_class])\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # data augumentation\n",
    "        cur_spec = self.specs[index]\n",
    "        if self.d_type == \"train\":\n",
    "            cur_spec = specaug(cur_spec)\n",
    "\n",
    "        return cur_spec, self.labels[index], self.fns[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        #         length of the whole dataset\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "# transform data from raw audio to spectrogram\n",
    "def get_melspec(file_path, sr=8000, top_db=80):\n",
    "    #print(file_path)\n",
    "    wav, sr = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    wav = np.pad(wav, int(np.ceil((2 * sr - wav.shape[0]) / 2)), mode='reflect')\n",
    " \n",
    "    spec = librosa.feature.melspectrogram(y=wav, sr=sr, n_fft=256, hop_length=64)\n",
    "   \n",
    "    spec = librosa.power_to_db(spec, top_db=top_db)\n",
    "    return spec\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e98c1-98c2-4d6b-9cbd-78f96fc6a5e8",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe62f6-4248-4a26-996a-98e8ae350bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv-s for classification folders\n",
    "# Fname,Genera,Species\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# create folders if not exist\n",
    "os.makedirs(os.path.dirname(train_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(valid_csv), exist_ok=True)\n",
    "\n",
    "\n",
    "def generate_csv(folder_path, output_csv):\n",
    "    \"\"\"\n",
    "    generate csv from paths.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    label_list=set()\n",
    "\n",
    "    # for all subfolders and files\n",
    "    for species in os.listdir(folder_path):\n",
    "        label_list.add(species)\n",
    "        \n",
    "        species_path = os.path.join(folder_path, species)\n",
    "        if os.path.isdir(species_path):\n",
    "            for fname in os.listdir(species_path):\n",
    "                # add files with their data\n",
    "                if os.path.isfile(os.path.join(species_path, fname)):\n",
    "                    data.append({\n",
    "                        \"Fname\": os.path.join(species_path, fname).replace(\"\\\\\", \"/\"),\n",
    "                        \"Genera\": \"\",\n",
    "                        \"Species\": species\n",
    "                    })\n",
    "\n",
    "    # write out CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"Fname\", \"Genera\", \"Species\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    return {key: idx for idx, key in enumerate(label_list)}\n",
    "\n",
    "# Train CSV\n",
    "label_list=generate_csv(train_folder, train_csv)\n",
    "print(f\"Train CSV is created: {train_csv}\")\n",
    "\n",
    "# Validation CSV\n",
    "generate_csv(valid_folder, valid_csv)\n",
    "print(f\"Validation CSV is created: {valid_csv}\")\n",
    "\n",
    "print(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49c369-38fd-452f-8fd1-6363b983d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, valid_loader, epochs, lf, optimizer):\n",
    "    sched = optim.lr_scheduler.CosineAnnealingLR(optimizer, 200, 0)\n",
    "    best_valid_acc = 0\n",
    "    best_model_report = ''\n",
    "\n",
    "    output_file = open(train_prefix+'output_big.txt', 'w+')\n",
    "    output_file.write('start...')\n",
    "    output_file.write('\\n')\n",
    "    output_file.close()\n",
    "    print('start...')\n",
    "    # training procedure\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_val = 0\n",
    "        true_running = 0\n",
    "        total_running = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            #print(data)\n",
    "            x, gt = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            predicted = model(x)\n",
    "            loss = lf(predicted, gt)\n",
    "\n",
    "            result, predicted_class = torch.max(predicted, 1)\n",
    "            true_running += (predicted_class == gt).sum()\n",
    "            total_running += predicted_class.shape[0]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_val += loss.item()\n",
    "\n",
    "        train_loss = loss_val / len(train_loader)\n",
    "        accuracy = torch.true_divide(true_running, total_running)\n",
    "        print(f'Epoch - {epoch} Train - Loss : {train_loss} Accuracy : {accuracy}')\n",
    "        output_file = open(train_prefix+'output_big.txt', 'a')\n",
    "        output_file.write(f'Epoch {epoch}/{epochs} - Train')\n",
    "        output_file.write(f'loss: {train_loss}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f'accuracy: {accuracy}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.close()\n",
    "\n",
    "        sched.step()\n",
    "        model.eval()\n",
    "\n",
    "        # validating procedure\n",
    "        valid_loss_val = 0\n",
    "        valid_true_running = 0\n",
    "        valid_total_running = 0\n",
    "        y_pred = np.array([])\n",
    "        y_test = np.array([])\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, gt = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.long)\n",
    "            predicted = model(x)\n",
    "            loss = lf(predicted, gt)\n",
    "\n",
    "            result, predicted_class = torch.max(predicted, 1)\n",
    "            valid_true_running += (predicted_class == gt).sum()\n",
    "            valid_total_running += predicted_class.shape[0]\n",
    "\n",
    "            valid_loss_val += loss.item()\n",
    "\n",
    "            y_pred = np.append(y_pred, predicted_class.cpu().detach().numpy())\n",
    "            y_test = np.append(y_test, gt.cpu().detach().numpy())\n",
    "\n",
    "        # calculating measurements\n",
    "        valid_loss = valid_loss_val / len(train_loader)\n",
    "        accuracy = torch.true_divide(valid_true_running, valid_total_running)\n",
    "        print(f'Epoch - {epoch} Validation - Loss : {valid_loss} Accuracy : {accuracy}')\n",
    "\n",
    "        # accuracy and loss\n",
    "        output_file = open(train_prefix+'output_big.txt', 'a')\n",
    "        output_file.write(f'Epoch {epoch}/{epochs} - Validation')\n",
    "        output_file.write(f'loss: {valid_loss}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f'accuracy: {accuracy}')\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # precision, recall, f1-score\n",
    "        output_file.write('\\nClassification Report\\n')\n",
    "        output_file.write(classification_report(y_test, y_pred, zero_division=0))\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        output_file.write('\\nConfusion Matrix\\n')\n",
    "        output_file.write(str(conf_matrix))\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # time usage for each epoch\n",
    "        end_time = time.time()\n",
    "        usage_time = end_time - start_time\n",
    "        output_file.write(f'Time usage: {usage_time} secs')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        output_file.close()\n",
    "\n",
    "        # save best model and its performance report, can be used for futher training\n",
    "        \n",
    "        # Save best loss model\n",
    "        if epoch == 1 or valid_loss < best_loss_val:\n",
    "            best_loss_val = valid_loss\n",
    "            torch.save(model.state_dict(), f'./{train_prefix}checkpoints/best_loss_{epoch}.pth')\n",
    "\n",
    "        # Save best accuracy model\n",
    "        if accuracy > best_valid_acc:\n",
    "            best_valid_acc = accuracy\n",
    "            best_model_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "            torch.save(model.state_dict(), f'./{train_prefix}checkpoints/big_{epoch}.pth')\n",
    "\n",
    "        # Save the last model\n",
    "        torch.save(model.state_dict(), f'./{train_prefix}checkpoints/last_model.pth')\n",
    "\n",
    "        # report the best training model\n",
    "        if epoch == epochs:\n",
    "            output_file = open(train_prefix+'output.txt', 'a')\n",
    "            output_file.write(f'End Training Overall Report')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'Best Validation Accuracy: {best_valid_acc}')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'Classification Report: {best_model_report}')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'The best model is saved under resnet_attention.pth')\n",
    "            output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f890a-d4b6-4d77-ab56-11170ccc43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b371e-3e0f-4424-9e3c-687e2cdb1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_prefix+\"checkpoints\" not in os.listdir(\"./\"):\n",
    "    os.mkdir(f\"./{train_prefix}checkpoints\")\n",
    "else:\n",
    "    print(\"Checkpoints folder is exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9095ba-4e01-4ed2-8c9a-36e8a660fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls_num=len(label_list)\n",
    "\n",
    "train_data = ListDataset(train_csv, label_list, \"train\")\n",
    "vali_data = ListDataset(valid_csv, label_list, \"validation\")\n",
    "\n",
    "print('loading training data')\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "print('loading validation data')\n",
    "vali_loader = DataLoader(vali_data, batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44926b6c-fe9a-4ff0-8d60-2f8bf7b7a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1  # input data are 1 channel, mono\n",
    "num_residual_blocks = 5  # B = 5\n",
    "base_filters = 32  # P = 32\n",
    "kernel_size = (5, 5)  # K = (5, 5)\n",
    "\n",
    "# initialize model\n",
    "model = ProposedModel(input_channels, num_residual_blocks, base_filters, kernel_size, cls_num)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce79f7-8ecb-4294-8b53-a519331f953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize optimizer és loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#train\n",
    "train(model, device, train_loader, vali_loader, epochs, loss_function, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f4984-451e-467e-b2e9-c11ec8597e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d21e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
