{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82164c3-cd8f-48cf-9595-426c356d47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_prefix=\"multiclass_indep_classifier_\"\n",
    "\n",
    "train_folder=\"./train-val-independent/train/\"\n",
    "valid_folder=\"./train-val-independent/validation/\"\n",
    "train_csv = \"./csv_resnet_indep/trainData.csv\"\n",
    "valid_csv = \"./csv_resnet_indep/valiData.csv\"\n",
    "\n",
    "b_selfattention=True\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 1e-3\n",
    "epochs = 500\n",
    "\n",
    "start_model_path = None #\"c:/PROJECTS/szunyog/b_mosquito/b_mosquito_simple_classifier-1_checkpoints/best_loss_99.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f4f87-90ba-4d24-8399-d65d29ecebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataPreprocess\n",
    "import model_modified\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe62f6-4248-4a26-996a-98e8ae350bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv-s for classification folders\n",
    "# Fname,Genera,Species\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# create folders for csvs\n",
    "os.makedirs(os.path.dirname(train_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(valid_csv), exist_ok=True)\n",
    "\n",
    "\n",
    "def generate_csv(folder_path, output_csv):\n",
    "    \"\"\"\n",
    "    generate csv from paths.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    label_list=set()\n",
    "\n",
    "    # for all subfolders and files\n",
    "    for species in os.listdir(folder_path):\n",
    "        label_list.add(species)\n",
    "        \n",
    "        species_path = os.path.join(folder_path, species)\n",
    "        if os.path.isdir(species_path):\n",
    "            for fname in os.listdir(species_path):\n",
    "                # add files with their data\n",
    "                if os.path.isfile(os.path.join(species_path, fname)):\n",
    "                    data.append({\n",
    "                        \"Fname\": os.path.join(species_path, fname).replace(\"\\\\\", \"/\"),\n",
    "                        \"Genera\": \"\",\n",
    "                        \"Species\": species\n",
    "                    })\n",
    "\n",
    "    # write out CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"Fname\", \"Genera\", \"Species\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    return {key: idx for idx, key in enumerate(label_list)}\n",
    "\n",
    "# Train CSV\n",
    "label_list=generate_csv(train_folder, train_csv)\n",
    "print(f\"Train CSV is created: {train_csv}\")\n",
    "\n",
    "# Validation CSV\n",
    "generate_csv(valid_folder, valid_csv)\n",
    "print(f\"Validation CSV is created: {valid_csv}\")\n",
    "\n",
    "print(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49c369-38fd-452f-8fd1-6363b983d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, valid_loader, epochs, lf, optimizer):\n",
    "    sched = optim.lr_scheduler.CosineAnnealingLR(optimizer, 200, 0)\n",
    "    best_valid_acc = 0\n",
    "    best_model_report = ''\n",
    "\n",
    "    output_file = open(train_prefix+'output_big.txt', 'w+')\n",
    "    output_file.write('start...')\n",
    "    output_file.write('\\n')\n",
    "    output_file.close()\n",
    "    print('start...')\n",
    "    # training procedure\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_val = 0\n",
    "        true_running = 0\n",
    "        total_running = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            #print(data)\n",
    "            x, gt = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            predicted = model(x)\n",
    "            loss = lf(predicted, gt)\n",
    "\n",
    "            result, predicted_class = torch.max(predicted, 1)\n",
    "            true_running += (predicted_class == gt).sum()\n",
    "            total_running += predicted_class.shape[0]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_val += loss.item()\n",
    "\n",
    "        train_loss = loss_val / len(train_loader)\n",
    "        accuracy = torch.true_divide(true_running, total_running)\n",
    "        print(f'Epoch - {epoch} Train - Loss : {train_loss} Accuracy : {accuracy}')\n",
    "        output_file = open(train_prefix+'output_big.txt', 'a')\n",
    "        output_file.write(f'Epoch {epoch}/{epochs} - Train')\n",
    "        output_file.write(f'loss: {train_loss}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f'accuracy: {accuracy}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.close()\n",
    "\n",
    "        sched.step()\n",
    "        model.eval()\n",
    "\n",
    "        # validating procedure\n",
    "        valid_loss_val = 0\n",
    "        valid_true_running = 0\n",
    "        valid_total_running = 0\n",
    "        y_pred = np.array([])\n",
    "        y_test = np.array([])\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, gt = data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.long)\n",
    "            predicted = model(x)\n",
    "            loss = lf(predicted, gt)\n",
    "\n",
    "            result, predicted_class = torch.max(predicted, 1)\n",
    "            valid_true_running += (predicted_class == gt).sum()\n",
    "            valid_total_running += predicted_class.shape[0]\n",
    "\n",
    "            valid_loss_val += loss.item()\n",
    "\n",
    "            y_pred = np.append(y_pred, predicted_class.cpu().detach().numpy())\n",
    "            y_test = np.append(y_test, gt.cpu().detach().numpy())\n",
    "\n",
    "        # calculating measurements\n",
    "        valid_loss = valid_loss_val / len(train_loader)\n",
    "        accuracy = torch.true_divide(valid_true_running, valid_total_running)\n",
    "        print(f'Epoch - {epoch} Validation - Loss : {valid_loss} Accuracy : {accuracy}')\n",
    "\n",
    "        # accuracy and loss\n",
    "        output_file = open(train_prefix+'output_big.txt', 'a')\n",
    "        output_file.write(f'Epoch {epoch}/{epochs} - Validation')\n",
    "        output_file.write(f'loss: {valid_loss}')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f'accuracy: {accuracy}')\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # precision, recall, f1-score\n",
    "        output_file.write('\\nClassification Report\\n')\n",
    "        output_file.write(classification_report(y_test, y_pred, zero_division=0))\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        output_file.write('\\nConfusion Matrix\\n')\n",
    "        output_file.write(str(conf_matrix))\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        # time usage for each epoch\n",
    "        end_time = time.time()\n",
    "        usage_time = end_time - start_time\n",
    "        output_file.write(f'Time usage: {usage_time} secs')\n",
    "        output_file.write('\\n')\n",
    "        output_file.write('\\n')\n",
    "\n",
    "        output_file.close()\n",
    "\n",
    "        # save best model and its performance report, can be used for futher training\n",
    "        \n",
    "        # Save best loss model\n",
    "        if epoch == 1 or valid_loss < best_loss_val:\n",
    "            best_loss_val = valid_loss\n",
    "            torch.save(model.state_dict(), f'./{train_prefix}checkpoints/best_loss_{epoch}.pth')\n",
    "\n",
    "        # Save best accuracy model\n",
    "        if accuracy > best_valid_acc:\n",
    "            best_valid_acc = accuracy\n",
    "            best_model_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "            torch.save(model.state_dict(), f'./{train_prefix}checkpoints/big_{epoch}.pth')\n",
    "\n",
    "        # Save the last model\n",
    "        torch.save(model.state_dict(), f'./{train_prefix}checkpoints/last_model.pth')\n",
    "\n",
    "        # report the best training model\n",
    "        if epoch == epochs:\n",
    "            output_file = open(train_prefix+'output.txt', 'a')\n",
    "            output_file.write(f'End Training Overall Report')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'Best Validation Accuracy: {best_valid_acc}')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'Classification Report: {best_model_report}')\n",
    "            output_file.write('\\n')\n",
    "            output_file.write(f'The best model is saved under resnet_attention.pth')\n",
    "            output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f890a-d4b6-4d77-ab56-11170ccc43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b371e-3e0f-4424-9e3c-687e2cdb1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_prefix+\"checkpoints\" not in os.listdir(\"./\"):\n",
    "    os.mkdir(f\"./{train_prefix}checkpoints\")\n",
    "else:\n",
    "    print(\"Checkpoints folder is exist.\")\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9095ba-4e01-4ed2-8c9a-36e8a660fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls_num=len(label_list)\n",
    "\n",
    "train_data = dataPreprocess.ListDataset(train_csv, label_list, \"train\")\n",
    "vali_data = dataPreprocess.ListDataset(valid_csv, label_list, \"validation\")\n",
    "\n",
    "print('loading training data')\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "print('loading validation data')\n",
    "vali_loader = DataLoader(vali_data, batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e490ae-7d73-4482-840c-eaaa5788283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained allready fora a binary classification\n",
    "\n",
    "if start_model_path is not None: \n",
    "    resnet_model = model_modified.resnet18_attention(1, 2, b_selfattention=b_selfattention)\n",
    "\n",
    "    resnet_model.load_state_dict(torch.load(start_model_path))\n",
    "    # redefine classification layer\n",
    "    resnet_model.decoder.decoder[3] = nn.Linear(in_features=128, out_features=cls_num, bias=True)\n",
    "\n",
    "    # initialize weights for the last layer\n",
    "    nn.init.xavier_uniform_(resnet_model.decoder.decoder[3].weight)\n",
    "    nn.init.zeros_(resnet_model.decoder.decoder[3].bias)\n",
    "else:\n",
    "    resnet_model = model_modified.resnet18_attention(1, cls_num, b_selfattention=b_selfattention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce79f7-8ecb-4294-8b53-a519331f953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "resnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f4984-451e-467e-b2e9-c11ec8597e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet_model.to(device)\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(resnet_model, device, train_loader, vali_loader, epochs, loss_function, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d21e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
